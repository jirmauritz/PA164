 A robot distributes promotional literature calling for a ban on fully autonomous weapons in Parliament Square on April 23, 2013, in London. The 'Campaign to Stop Killer Robots' is calling for a pre-emptive ban on lethal robot weapons that could attack targets without human intervention On Tuesday in Geneva, the United Nations will convene a meeting on the use of "killer robots" -- lethal autonomous weapons that in theory could select targets and attack them without direct human mediation. To be clear, killer robots don't yet exist, but a host of countries are developing technology that could make them a reality in the not so distant future. Quite a few organizations and activists want to prevent that from ever happening. What are these machines? An article in Foreign Affairs outlines the sort of technology that is moving us toward a future populated by killer robots: The Samsung Techwin security surveillance guard robots, which South Korea uses in the demilitarized zone it shares with North Korea, can detect targets through infrared sensors. Although they are currently operated by humans, the robots have an automatic feature that can detect body heat in the demilitarized zone and fire with an onboard machine gun without the need for human operators. The U.S. firm Northrop Grumman has developed an autonomous drone, the X-47B, which can travel on a preprogrammed flight path while being monitored by a pilot on a ship. It is expected to enter active naval service by 2019. Israel, meanwhile, is developing an armed drone known as the Harop that could select targets on its own with a special sensor, after loitering in the skies for hours. On Monday, a number of prominent Nobel laureates, including Archbishop Desmond Tutu of South Africa and former Polish president Lech Walesa, jointly issued a letter calling for a ban on these sorts of weapons: "It is unconscionable that human beings are expanding research and development of lethal machines that would be able to kill people without human intervention," the statement read. Human Rights Watch (HRW), meanwhile, published a report, titled "Shaking the Foundation: The Human Implications of Killer Robots," also advocating a ban through an international treaty. “In policing, as well as war, human judgment is critically important to any decision to use a lethal weapon,” Steve Goose, HRW's arms division director, said in a press release. “Governments need to say no to fully autonomous weapons for any purpose and to preemptively ban them now, before it is too late.” Killer robots are, in a sense, the next iteration of drones -- and the debate that surrounds their potential use will likely be as contentious. The idea of such technology evokes now-cliched images of a dystopian future, where Terminator-type shooting machines run amok among cowering humans. For advocates of a ban, the issue hinges on a philosophical and moral conundrum: Who is responsible when a fully autonomous robot kills an innocent? How can we allow a world where decisions over life and death are entirely mechanized? "Autonomous weapons systems cannot be guaranteed to predictably comply with international law," said Noel Sharkey, a roboticist who plays a key role in the Campaign to Stop Killer Robots, speaking to the BBC. But Ronald Arkin, a roboticist at the Georgia Institute of Technology, sees it differently. Arkin will debate Sharkey in Geneva and is among a contingent of experts who believe that, far from what their nickname suggests, killer robots may help reduce collateral damage and loss of life in conflict situations. In the heat of battle, human action can lead to hideous atrocities. "It is not my belief that an unmanned system will be able to be perfectly ethical in the battlefield," Arkin said in 2007. "But I am convinced that they can perform more ethically than human soldiers." Arkin suggests it will be possible to develop ethical software to ensure killer robots use lethal force within a narrow, carefully calibrated set of circumstances. Researchers from a number of American universities are already collaborating with the U.S. Navy to develop technology that could teach a robot right from wrong. Joshua Foust, a Washington-based defense analyst who resists blanket bans on drones and other such forms of unmanned weaponry, argues that, like drones, killer robots are just one more platform or tool for war: The real debate should surround the philosophy behind utilizing these systems: what are they designed to do, and can they be made to do it more effectively? Humans are imperfect – targets may be misidentified, vital intelligence can be discounted because of cognitive biases, and outside information just might not be available to make a decision. Autonomous systems can dramatically improve that process so that civilians are actually much better protected than by human inputs alone Critics would contest that the present controversies generated by drone strikes in Yemen and Pakistan are bad enough, with angry civilians caught between complicit local governments, militant groups and the long arm of American foreign policy whirring overhead. Deployed in such a setting, killer robots would only darken the picture, making it even more difficult to hold militaries accountable, argues Bonnie Docherty, the author of the new HRW report. “It would be very difficult for families to obtain retribution or remedy for the unlawful killing of a relative by such a machine,” she says in the press release issued Monday. That may or may not be true, but many hope we'll never have to know for sure.
